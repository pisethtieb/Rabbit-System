"use strict";

function error(err) {
    return logger(err.message);
}

function readMetadata(collection, metadata, next) {
    var doc, t = metadata + collection.collectionName;
    if (fs.existsSync(t) === !1) return error(new Error("missing metadata for " + collection.collectionName)), 
    next();
    try {
        doc = JSON.parse(fs.readFileSync(t, {
            encoding: "utf8"
        }));
    } catch (err) {
        return error(err), next();
    }
    if (0 === doc.length) return next();
    for (var i = 0, c = 0, ii = doc.length; ii > i; ++i) {
        var indexes = doc[i];
        if (/^_id/.test(indexes.name) !== !0) {
            var name = indexes.name.substr(0, indexes.name.length - 2);
            collection.createIndex(name, indexes, function(err) {
                err && error(err), ++c === ii && next();
            });
        } else ++c === ii && next();
    }
}

function makeDir(path, next) {
    return fs.stat(path, function(err, stats) {
        return err && "ENOENT" === err.code ? (logger("make dir at " + path), fs.mkdir(path, function(err) {
            return next(err, path);
        })) : stats && stats.isDirectory() === !1 ? (logger("unlink file at " + path), fs.unlink(path, function() {
            return logger("make dir at " + path), fs.mkdir(path, function(err) {
                return next(err, path);
            });
        })) : next(null, path);
    });
}

function rmDir(path, next) {
    fs.readdirSync(path).forEach(function(first) {
        var database = path + first;
        if (fs.statSync(database).isDirectory() !== !1) {
            var metadata = "", collections = fs.readdirSync(database);
            return fs.existsSync(database + "/.metadata") === !0 && (metadata = database + "/.metadata/", 
            delete collections[collections.indexOf(".metadata")]), collections.forEach(function(second) {
                var collection = database + "/" + second;
                if (fs.statSync(collection).isDirectory() !== !1) return fs.readdirSync(collection).forEach(function(third) {
                    var document = collection + "/" + third;
                    return fs.unlinkSync(document), next ? next(null, document) : "";
                }), "" !== metadata && fs.unlinkSync(metadata + second), fs.rmdirSync(collection);
            }), "" !== metadata && fs.rmdirSync(metadata), fs.rmdirSync(database);
        }
    });
}

function fromJson(collection, collectionPath, next) {
    var docs = fs.readdirSync(collectionPath), last = docs.length, index = 0;
    return 1 > last ? next() : docs.forEach(function(docName) {
        var doc, docPath = collectionPath + docName;
        if (fs.statSync(docPath).isFile() === !1) {
            var err = new Error("document is not a valid format");
            return last === ++index ? next(err) : error(err);
        }
        try {
            doc = JSON.parse(fs.readFileSync(docPath, {
                encoding: "utf8"
            }));
        } catch (err) {
            return last === ++index ? next(err) : error(err);
        }
        return collection.save(doc, function(err) {
            return err ? last === ++index ? next(err) : error(err) : last === ++index ? next() : null;
        });
    });
}

function fromBson(collection, collectionPath, next) {
    var docs = fs.readdirSync(collectionPath), last = docs.length, index = 0;
    return 1 > last ? next() : docs.forEach(function(docName) {
        var doc, docPath = collectionPath + docName;
        if (fs.statSync(docPath).isFile() === !1) {
            var err = new Error("document is not a valid format");
            return last === ++index ? next(err) : error(err);
        }
        try {
            doc = BSON.deserialize(fs.readFileSync(docPath, {
                encoding: null
            }));
        } catch (err) {
            return last === ++index ? next(err) : error(err);
        }
        return collection.save(doc, function(err) {
            return err ? last === ++index ? next(err) : error(err) : last === ++index ? next() : null;
        });
    });
}

function allCollections(db, name, metadata, parser, next) {
    var collections = fs.readdirSync(name), last = collections.length, index = 0;
    return 1 > last ? next(null) : (collections.indexOf(".metadata") >= 0 && (delete collections[collections.indexOf(".metadata")], 
    last--), collections.forEach(function(collectionName) {
        var collectionPath = name + collectionName;
        if (!fs.statSync(collectionPath).isDirectory()) {
            var err = new Error(collectionPath + " is not a directory");
            return last === ++index ? next(err) : error(err);
        }
        return db.createCollection(collectionName, function(err, collection) {
            return err ? last === ++index ? next(err) : error(err) : (logger("select collection " + collectionName), 
            meta(collection, metadata, function() {
                return parser(collection, collectionPath + "/", function(err) {
                    return err ? last === ++index ? next(err) : error(err) : last === ++index ? next(null) : null;
                });
            }));
        });
    }));
}

function someCollections(db, collections, next) {
    var last = collections.length, index = 0;
    return 1 > last ? next(null) : collections.forEach(function(collection) {
        return db.collection(collection, function(err, collection) {
            return logger("select collection " + collection.collectionName), err ? last === ++index ? next(err) : error(err) : void collection.drop(function(err) {
                return err ? last === ++index ? next(err) : error(err) : last === ++index ? next(null) : null;
            });
        });
    });
}

function wrapper(my) {
    function callback() {
        logger("restore stop"), my.tar && rmDir(my.dir), null !== my.callback && (logger("callback run"), 
        my.callback());
    }
    function go(root) {
        return my.metadata === !0 && (metadata = root + ".metadata/"), require("mongodb").MongoClient.connect(my.uri, my.options, function(err, db) {
            function next(err) {
                return err ? (error(err), logger("db close"), db.close(), callback()) : discriminator(db, root, metadata, parser, function(err) {
                    return err && error(err), logger("db close"), db.close(), callback();
                });
            }
            return logger("db open"), err ? error(err) : my.drop === !0 ? (logger("drop database"), 
            db.dropDatabase(function(err) {
                return next(err);
            })) : my.dropCollections ? (logger("drop collections"), Array.isArray(my.dropCollections) === !0 ? someCollections(db, my.dropCollections, function(err) {
                return next(err);
            }) : db.collections(function(err, collections) {
                err && error(err), my.dropCollections = [];
                for (var i = 0, ii = collections.length; ii > i; i++) /^system./.test(collections[i].collectionName) === !1 && my.dropCollections.push(collections[i].collectionName);
                return someCollections(db, my.dropCollections, function(err) {
                    return next(err);
                });
            })) : next();
        });
    }
    var parser;
    if ("function" == typeof my.parser) parser = my.parser; else switch (my.parser) {
      case "bson":
        BSON = require("bson"), BSON = new BSON.BSONPure.BSON(), parser = fromBson;
        break;

      case "json":
        parser = fromJson;
        break;

      default:
        throw new Error("missing parser option");
    }
    var discriminator = allCollections;
    if (null === my.logger) logger = function() {}; else {
        logger = require("logger-request")({
            filename: my.logger,
            standalone: !0,
            winston: {
                logger: "_mongo_r" + my.logger,
                level: "info",
                json: !1
            }
        }), logger("restore start");
        var log = require("mongodb").Logger;
        log.setLevel("info"), log.setCurrentLogger(function(msg) {
            return logger(msg);
        });
    }
    var metadata = "";
    return meta = my.metadata === !0 ? readMetadata : function(a, b, c) {
        return c();
    }, my.tar ? makeDir(my.dir, function() {
        var extractor = require("tar").Extract({
            path: my.dir
        }).on("error", error).on("end", function() {
            for (var dirs = fs.readdirSync(my.dir), i = 0, ii = dirs.length; ii > i; i++) {
                var t = my.dir + dirs[i];
                if (fs.statSync(t).isFile() === !1) return go(t + "/");
            }
        });
        null !== my.stream ? (logger("get tar file from stream"), my.stream.pipe(extractor)) : (logger("open tar file at " + my.root + my.tar), 
        fs.createReadStream(my.root + my.tar).on("error", error).pipe(extractor));
    }) : go(my.root);
}

function restore(options) {
    var resolve = require("path").resolve, opt = options || Object.create(null);
    if (!opt.uri) throw new Error("missing uri option");
    if (!opt.stream) {
        if (!opt.root) throw new Error("missing root option");
        if (!fs.existsSync(opt.root) || !fs.statSync(opt.root).isDirectory()) throw new Error("root option is not a directory");
    }
    var my = {
        dir: __dirname + "/dump/",
        uri: String(opt.uri),
        root: resolve(String(opt.root)) + "/",
        stream: opt.stream || null,
        parser: opt.parser || "bson",
        callback: "function" == typeof opt.callback ? opt.callback : null,
        tar: "string" == typeof opt.tar ? opt.tar : null,
        logger: "string" == typeof opt.logger ? resolve(opt.logger) : null,
        metadata: Boolean(opt.metadata),
        drop: Boolean(opt.drop),
        dropCollections: Boolean(opt.dropCollections) ? opt.dropCollections : null,
        options: "object" == typeof opt.options ? opt.options : {}
    };
    return my.stream && (my.tar = !0), wrapper(my);
}

var fs = require("fs"), BSON, logger, meta;

module.exports = restore;
